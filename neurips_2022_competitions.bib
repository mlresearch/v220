@Proceedings{NEURIPS-COMPETITIONS-2022,
  booktitle =	 {Proceedings of the NeurIPS 2022 Competitions Track},
  name =	 {NeurIPS 2022 Competition Track},
  shortname =	 {NeurIPS 2022: Competitions},
  editor =	 {Marco Ciccone and Gustavo Stolovitzky and Jacob
                  Albrecht},
  volume =	 220,
  year =	 2022,
  start =	 {2022-11-28},
  end =		 {2022-12-09},
  published =	 {2022-08-31},
  conference_url ={https://neurips.cc/Conferences/2022},
  address =	 {New Orleans, LA, Online},
  sections =	 {Preface|Competitions}
}

@InProceedings{Ciccone23a,
  title =	 {NeurIPS 2022 Competition Track Revised Selected
                  Papers},
  author =	 {Marco Ciccone and Gustavo Stolovitzky and Jacob
                  Albrecht},
  pages =	 {i-i},
  abstract =	 {Introduction to this volume.},
  section =	 {Preface}
}

@InProceedings{Yip23a,
  title =	 {Lessons Learned from Ariel Data Challenge 2022 -
                  Inferring Physical Properties of Exoplanets From
                  Next-Generation Telescopes},
  author =	 {Yip, Kai Hou and Changeat, Quentin and Waldmann,
                  Ingo and Unlu, Eyup B. and Forestano, Roy T. and
                  Roman, Alexander and Matcheva, Katia and Matchev,
                  Konstantin T. and Stefanov, Stefan and Podsztavek,
                  Ond\vrej and Morvan, Mario and Nikolaou, Nikolaos
                  and Al-Refaie, Ahmed and Jenner, Clare and Johnson,
                  Chris and Tsiaras, Angelos and Edwards, Billy and
                  Alves de Oliveira, Catarina and Thiyagalingam, Jeyan
                  and Lagage, Pierre-Olivier and Cho, James and
                  Tinetti, Giovanna},
  pages =	 {1-17},
  abstract =	 {Exo-atmospheric studies, i.e. the study of
                  exoplanetary atmospheres, is an emerging frontier in
                  Planetary Science. To understand the physical
                  properties of hundreds of exoplanets, astronomers
                  have traditionally relied on sampling-based
                  methods. However, with the growing number of
                  exoplanet detections (i.e. increased data quantity)
                  and advancements in technology from telescopes such
                  as JWST and Ariel (i.e. improved data quality),
                  there is a need for more scalable data analysis
                  techniques. The Ariel Data Challenge 2022 aims to
                  find interdisciplinary solutions from the NeurIPS
                  community. Results from the challenge indicate that
                  machine learning (ML) models have the potential to
                  provide quick insights for thousands of planets and
                  millions of atmospheric models. However, the machine
                  learning models are not immune to data drifts, and
                  future research should investigate ways to quantify
                  and mitigate their negative impact.},
  section =	 {Competitions}
}

@InProceedings{Liu23a,
  title =	 {The NeurIPS 2022 Neural MMO Challenge: A Massively
                  Multiagent Competition with Specialization and
                  Trade},
  author =	 {Liu, Enhong and Suarez, Joseph and You, Chenhui and
                  Wu, Bo and Chen, Bingcheng and Hu, Jun and Chen,
                  Jiaxin and Zhu, Xiaolong and Zhu, Clare and
                  Togelius, Julian and Mohanty, Sharada and Hong,
                  Weijun and Du, Rui and Zhang, Yibing and Wang,
                  Qinwen and Li, Xinhang and Yuan, Zheng and Li, Xiang
                  and Huang, Yuejia and Zhang, Kun and Yang, Hanhui
                  and Tang, Shiqi and Isola, Phillip},
  pages =	 {18-34},
  abstract =	 {In this paper, we present the results of the
                  NeurIPS-2022 Neural MMO Challenge, which attracted
                  500 participants and received over 1,600
                  submissions. Like the previous IJCAI-2022 Neural MMO
                  Challenge, it involved agents from 16 populations
                  surviving in procedurally generated worlds by
                  collecting resources and defeating opponents. This
                  year's competition runs on the latest v1.6 Neural
                  MMO, which introduces new equipment, combat,
                  trading, and a better scoring system. These elements
                  combine to pose additional robustness and
                  generalization challenges not present in previous
                  competitions. This paper summarizes the design and
                  results of the challenge, explores the potential of
                  this environment as a benchmark for learning
                  methods, and presents some practical reinforcement
                  learning training approaches for complex tasks with
                  sparse rewards. Additionally, we have open-sourced
                  our baselines, including environment wrappers,
                  benchmarks, and visualization tools for future
                  research.},
  section =	 {Competitions}
}

@InProceedings{Kool23a,
  title =	 {The EURO Meets NeurIPS 2022 Vehicle Routing
                  Competition},
  author =	 {Kool, Wouter and Bliek, Laurens and Numeroso, Danilo
                  and Zhang, Yingqian and Catshoek, Tom and Tierney,
                  Kevin and Vidal, Thibaut and Gromicho, Joaquim},
  pages =	 {35-49},
  abstract =	 {Solving vehicle routing problems (VRPs) is an
                  essential task for many industrial
                  applications. Although VRPs have been traditionally
                  studied in the operations research (OR) domain, they
                  have lately been the subject of extensive work in
                  the machine learning (ML) community. Both the OR and
                  ML communities have begun to integrate ML into their
                  methods, but in vastly different ways. While the OR
                  community primarily relies on simplistic ML methods,
                  the ML community generally uses deep learning, but
                  fails to outperform OR baselines. To address this
                  gap, the <em>EURO Meets NeurIPS 2022 Vehicle Routing
                  Competition</em> brought together the OR and ML
                  communities as a joint effort of several previous
                  competitions to solve a challenging VRP variant on
                  real-world data provided by ORTEC, a leading
                  provider of vehicle routing software. The challenge
                  focuses on both a "classic" deterministic VRP with
                  time windows (VRPTW) and a dynamic version in which
                  new orders arrive over the course of a day. Over 50
                  teams submitted solutions over a 13-week submission
                  period, battling for not only the best performance
                  on the competition problems, but also for the
                  longest dominance of the leaderboard. The goals of
                  the competition were achieved, with both
                  state-of-the-art techniques in OR and ML playing a
                  significant role in several of the winning
                  submissions.},
  section =	 {Competitions}
}

@InProceedings{Carrion-Ojeda23a,
  title =	 {NeurIPS'22 Cross-Domain MetaDL Challenge: Results
                  and lessons learned},
  author =	 {Carri\'{o}n-Ojeda, Dustin and Alam, Mahbubul and
                  Escalera, Sergio and Farahat, Ahmed and Ghosh,
                  Dipanjan and Gonzalez Diaz, Teresa and Gupta, Chetan
                  and Guyon, Isabelle and Ky, Jo\"el Roman and Lee,
                  Xian Yeow and Liu, Xin and Mohr, Felix and Nguyen,
                  Manh Hung and Pintelas, Emmanuel and Roth, Stefan
                  and Schaub-Meyer, Simone and Sun, Haozhe and Ullah,
                  Ihsan and Vanschoren, Joaquin and Vidyaratne,
                  Lasitha and Wu, Jiamin and Yin, Xiaotian},
  pages =	 {50-72},
  abstract =	 {Deep neural networks have demonstrated the ability
                  to outperform humans in multiple tasks, but they
                  often require substantial amounts of data and
                  computational resources. These resources may be
                  limited in certain fields. Meta-learning seeks to
                  overcome these challenges by utilizing past task
                  experiences to efficiently solve new tasks,
                  achieving better performance with limited training
                  data and modest computational resources. To further
                  advance the ChaLearn MetaDL competition series, we
                  organized the Cross-Domain MetaDL Challenge for
                  NeurIPS'22. This challenge aimed to solve ``any-way"
                  and ``any-shot" tasks from 10 domains through
                  cross-domain meta-learning. In this paper, authored
                  collaboratively by the competition organizers,
                  top-ranked participants, and external collaborators,
                  we describe the technical aspects of the
                  competition, baseline methods, and top-ranked
                  approaches that have been
                  open-sourced. Additionally, we provide a detailed
                  analysis of the competition results. Lessons learned
                  from this competition include the critical role of
                  pre-trained backbones, the necessity of preventing
                  overfitting, and the significance of using data
                  augmentation or domain adaptation techniques in
                  conjunction with extra optimizations to improve
                  performance.},
  section =	 {Competitions}
}

@InProceedings{Rasouli23a,
  title =	 {Driving SMARTS Competition at NeurIPS 2022: Insights
                  and Outcome},
  author =	 {Rasouli, Amir and Alizadeh, Soheil and Kotseruba,
                  Iuliia and Ma, Yi and Liang, Hebin and Tian, Yuan
                  and Huang, Zhiyu and Liu, Haochen and Wu, Jingda and
                  Goebel, Randy and Yang, Tianpei and Taylor, Matthew
                  E. and Paull, Liam and Chen, Xi},
  pages =	 {73-84},
  abstract =	 {The Driving SMARTS (Scalable Multi-Agent
                  Reinforcement Learning Training School) competition
                  was designed to address one of the major challenges
                  for autonomous driving (AD), namely adaptation to
                  distribution shift between data used for training
                  and inference and the problems caused by this shift
                  in real-world conditions.  The two key features of
                  the competition are 1) a two-track structure to
                  encourage and support a variety of approaches to
                  solving the problem, such as reinforcement learning,
                  offline learning, and other machine learning
                  methods; and 2) curated data for driving scenarios
                  of varying difficulty levels, from cruising to
                  unprotected turns at unsignalized intersections.
                  The competition attracted 87 participants in 53
                  teams. Top-ranking teams contributed a diverse set
                  of solutions highlighting the effectiveness of
                  different methodologies on safe motion planning for
                  AD. This paper provides an overview of the Driving
                  SMARTS competition, discusses its organisational and
                  design aspects, and presents the results, insights,
                  and promising directions for future research.},
  section =	 {Competitions}
}

@InProceedings{Nweye23a,
  title =	 {The CityLearn Challenge 2022: Overview, Results, and
                  Lessons Learned},
  author =	 {Nweye, Kingsley and Nagy, Zoltan and Mohanty,
                  Sharada and Chakraborty, Dipam and Sankaranarayanan,
                  Siva and Hong, Tianzhen and Dey, Sourav and Henze,
                  Gregor and Drgona, Jan and Lin, Fangquan and Jiang,
                  Wei and Zhang, Hanwei and Yi, Zhongkai and Zhang,
                  Jihai and Yang, Cheng and Motoki, Matthew and
                  Khongnawang, Sorapong and Ibrahim, Michael and
                  Zhumabekov, Abilmansur and May, Daniel and Yang,
                  Zhihu and Song, Xiaozhuang and Zhang, Han and Dong,
                  Xiaoning and Zheng, Shun and Bian, Jiang},
  pages =	 {85-103},
  abstract =	 {The shift to renewable power sources and building
                  electrification to decarbonize existing and emerging
                  building stock present unique challenges for the
                  power grid. Building loads and flexible resources
                  e.g. batteries must be adequately managed
                  simultaneously to unlock the full flexibility
                  potential and reduce costs for all
                  stakeholders. Simple control algorithms based on
                  expert knowledge e.g. RBC, as well as, advanced
                  control algorithms e.g. MPC and RLC can be utilized
                  to intelligently manage flexible resources. The
                  CityLearn Challenge is an opportunity to compete in
                  investigating the potential of AI and distributed
                  control systems to tackle multiple problems within
                  the built-environment. The CityLearn Challenge 2022
                  is the third of its kind with the overall objective
                  of crowd-sourcing generalizable control policies
                  that improve energy, cost and environmental
                  objectives by taking advantage of batteries for load
                  shifting in a CityLearn digital twin of a real-world
                  grid-interactive neighborhood. Highlighted here are
                  the uniqueness of this third edition, baseline and
                  top solutions, and lessons learned for future
                  editions.},
  section =	 {Competitions}
}

@InProceedings{Bashkirova23a,
  title =	 {VisDA 2022 Challenge: Domain Adaptation for
                  Industrial Waste Sorting},
  author =	 {Bashkirova, Dina and Mishra, Samarth and Lteif,
                  Diala and Teterwak, Piotr and Kim, Donghyun and
                  Alladkani, Fadi and Akl, James and Calli, Berk and
                  Bargal, Sarah Adel and Saenko, Kate and Kim, Daehan and
                  Seo, Minseok and Jeon, YoungJin and Choi, Dong-Geol
                  and Ettedgui, Shahaf and Giryes, Raja and
                  Abu-Hussein, Shady and Xie, Binhui and Li, Shuang},
  pages =	 {104-118},
  abstract =	 {Label-efficient and reliable semantic segmentation
                  is essential for many real-life applications,
                  especially for industrial settings with high visual
                  diversity, such as waste sorting. In industrial
                  waste sorting, one of the biggest challenges is the
                  extreme diversity of the input stream depending on
                  factors like the location of the sorting facility,
                  the equipment available in the facility, and the
                  time of year, all of which significantly impact the
                  composition and visual appearance of the waste
                  stream. These changes in the data are called
                  ``visual domains'', and label-efficient adaptation
                  of models to such domains is needed for successful
                  semantic segmentation of industrial waste.  To test
                  the abilities of computer vision models on this
                  task, we present the \emph{VisDA 2022 Challenge on
                  Domain Adaptation for Industrial Waste Sorting}.
                  Our challenge incorporates a fully-annotated waste
                  sorting dataset, ZeroWaste, collected from two real
                  material recovery facilities in different locations
                  and seasons, as well as a novel procedurally
                  generated synthetic waste sorting dataset,
                  SynthWaste. In this competition, we aim to answer
                  two questions: 1) can we leverage domain adaptation
                  techniques to minimize the domain gap? and 2) can
                  synthetic data augmentation improve performance on
                  this task and help adapt to changing data
                  distributions? The results of the competition show
                  that industrial waste detection poses a real domain
                  adaptation problem, that domain generalization
                  techniques such as augmentations, ensembling, etc.,
                  improve the overall performance on the unlabeled
                  target domain examples, and that leveraging
                  synthetic data effectively remains an open
                  problem. See \url{https://ai.bu.edu/visda-2022/}},
  section =	 {Competitions}
}

@InProceedings{Gardner23a,
  title =	 {The Machine Reconnaissance Blind Chess Tournament of
                  NeurIPS 2022},
  author =	 {Gardner, Ryan W. and Perrotta, Gino and Shah, Anvay
                  and Kalyanakrishnan, Shivaram and Wang, Kevin A. and
                  Clark, Gregory and Bertram, Timo and F\"{u}rnkranz,
                  Johannes and M\"{u}ller, Martin and Garrison, Brady
                  P. and Dasgupta, Prithviraj and Rezaei, Saeid},
  pages =	 {119-132},
  abstract =	 {Reconnaissance Blind Chess is a game that plays like
                  regular chess but rather than continuously observing
                  the entire board, each player can only momentarily
                  and privately observe selected board regions.  It
                  has imperfect information and little common
                  knowledge.  The Johns Hopkins University Applied
                  Physics Laboratory (the game's creator) and several
                  partners organized the third NeurIPS machine
                  Reconnaissance Blind Chess competition in 2022 to
                  bring people together to attempt to tackle research
                  challenges presented by the game.  18 bots played
                  each other in 9,180 games (60 matches per bot pair)
                  over 4 days.  The top bot exceeded the performance
                  of all of last year's bots yet a practical, sound
                  (unexploitable) algorithm remains unknown.},
  section =	 {Competitions}
}

@InProceedings{Gurtler23a,
  title =	 {Real Robot Challenge 2022: Learning Dexterous
                  Manipulation from Offline Data in the Real World},
  author =	 {G\"urtler, Nico and Widmaier, Felix and Sancaktar,
                  Cansu and Blaes, Sebastian and Kolev, Pavel and
                  Bauer, Stefan and W\"uthrich, Manuel and Wulfmeier,
                  Markus and Riedmiller, Martin and Allshire, Arthur
                  and Wang, Qiang and McCarthy, Robert and Kim,
                  Hangyeol and Baek, Jongchan and Kwon, Wookyong and
                  Qian, Shanliang and Toshimitsu, Yasunori and
                  Michelis, Mike Yan and Kazemipour, Amirhossein and
                  Raayatsanati, Arman and Zheng, Hehui and Cangan,
                  Barnabasa Gavin and Sch\"olkopf, Bernhard and
                  Martius, Georg},
  pages =	 {133-150},
  abstract =	 {Experimentation on real robots is demanding in terms
                  of time and costs. For this reason, a large part of
                  the reinforcement learning (RL) community uses
                  simulators to develop and benchmark
                  algorithms. However, insights gained in simulation
                  do not necessarily translate to real robots, in
                  particular for tasks involving complex interactions
                  with the environment. The <em>Real Robot Challenge
                  2022</em> therefore served as a bridge between the
                  RL and robotics communities by allowing participants
                  to experiment remotely with a <em>real</em> robot -
                  as easily as in simulation.  In the last years,
                  offline reinforcement learning has matured into a
                  promising paradigm for learning from pre-collected
                  datasets, alleviating the reliance on expensive
                  online interactions. We therefore asked the
                  participants to learn two dexterous manipulation
                  tasks involving pushing, grasping, and in-hand
                  orientation from provided real-robot datasets. An
                  extensive software documentation and an initial
                  stage based on a simulation of the real set-up made
                  the competition particularly accessible. By giving
                  each team plenty of access budget to evaluate their
                  offline-learned policies on a cluster of seven
                  identical real TriFinger platforms, we organized an
                  exciting competition for machine learners and
                  roboticists alike.  In this work we state the rules
                  of the competition, present the methods used by the
                  winning teams and compare their results with a
                  benchmark of state-of-the-art offline RL algorithms
                  on the challenge datasets.},
  section =	 {Competitions}
}

@InProceedings{Roberts23a,
  title =	 {AutoML Decathlon: Diverse Tasks, Modern Methods, and
                  Efficiency at Scale},
  author =	 {Roberts, Nicholas and Guo, Samuel and Xu, Cong and
                  Talwalkar, Ameet and Lander, David and Tao, Lvfang
                  and Cai, Linhang and Niu, Shuaicheng and Heng,
                  Jianyu and Qin, Hongyang and Deng, Minwen and Hog,
                  Johannes and Pfefferle, Alexander and Shivakumar,
                  Sushil Ammanaghatta and Krishnakumar, Arjun and
                  Wang, Yubo and Sukthanker, Rhea and Hutter, Frank
                  and Hasanaj, Euxhen and Le, Tien-Dung and Khodak,
                  Mikhail and Nevmyvaka, Yuriy and Rasul, Kashif and
                  Sala, Frederic and Schneider, Anderson and Shen,
                  Junhong and Sparks, Evan},
  pages =	 {151-170},
  abstract =	 {The vision of Automated Machine Learning (AutoML) is
                  to produce high performing ML pipelines that require
                  very little human involvement or domain expertise to
                  use. Competitions and benchmarks have been critical
                  tools for accelerating progress in AutoML. However,
                  much of the prior work on AutoML competitions has
                  focused on well-studied domains in machine learning
                  such as vision and language---these are domains
                  which have benefited from several years of ML
                  pipeline design by domain experts, which brings the
                  usage of AutoML into question in the first
                  place. Recently, AutoML for diverse tasks has
                  emerged as an important research area that aims to
                  bring AutoML to the domains where it can have the
                  most impact: the long tail of ML tasks <em>beyond
                  vision and language</em>. We present a retrospective
                  report of the AutoML Decathlon---an AutoML for
                  diverse tasks competition hosted at NeurIPS
                  2022. The AutoML Decathlon presented participants
                  with a set of 10 machine learning tasks that are
                  diverse along several axes: domain, input dimension,
                  output dimension, output type, objective function,
                  and scale. Participants were tasked with developing
                  AutoML methods that performed well on a
                  <em>separate</em> set of 10 hidden diverse test
                  tasks within a certain time budget, so as to
                  discourage overfitting to the initial set of tasks
                  and to encourage efficiency. In this report, we
                  outline the details of the competition, discuss the
                  top-5 submissions, analyze the results, and compare
                  top submissions to additional state-of-the-art
                  baselines designed specifically for diverse
                  tasks. We conclude that the combination of existing
                  efficient AutoML techniques with modern advancements
                  in ML such as large-scale transfer learning, modern
                  architectures, and differentiable Neural
                  Architecture Search (NAS) is a promising direction
                  for AutoML for diverse tasks.},
  section =	 {Competitions}
}

@InProceedings{Milani23a,
  title =	 {Towards Solving Fuzzy Tasks with Human Feedback: A
                  Retrospective of the MineRL BASALT 2022 Competition},
  author =	 {Milani, Stephanie and Kanervisto, Anssi and
                  Ramanauskas, Karolis and Schulhoff, Sander and
                  Houghton, Brandon and Mohanty, Sharada and
                  Galbraith, Byron and Chen, Ke and Song, Yan and
                  Zhou, Tianze and Yu, Bingquan and Liu, He and Guan,
                  Kai and Hu, Yujing and Lv, Tangjie and Malato,
                  Federico and Leopold, Florian and Raut, Amogh and
                  Hautam\"aki, Ville and Melnik, Andrew and Ishida,
                  Shu and Henriques, Jo\~ao and Klassert, Robert and
                  Laurito, Walter and Cazzonelli, Lucas and Kulbach,
                  Cedric and Popovic, Nicholas and Schweizer, Marvin
                  and Novoseller, Ellen and Goecks, Vinicius and
                  Waytowich, Nicholas and Watkins, David and Miller,
                  Josh and Shah, Rohin},
  pages =	 {171-188},
  abstract =	 {To facilitate research in the direction of
                  fine-tuning foundation models from human feedback,
                  we held the MineRL BASALT Competition on Fine-Tuning
                  from Human Feedback at NeurIPS 2022. The BASALT
                  challenge asks teams to compete to develop
                  algorithms to solve tasks with hard-to-specify
                  reward functions in Minecraft. Through this
                  competition, we aimed to promote the development of
                  algorithms that use human feedback as channels to
                  learn the desired behavior. We describe the
                  competition and provide an overview of the top
                  solutions. We conclude by discussing the impact of
                  the competition and future directions for
                  improvement.},
  section =	 {Competitions}
}

@InProceedings{Ramamonjison23a,
  title =	 {NL4Opt Competition: Formulating Optimization
                  Problems Based on Their Natural Language
                  Descriptions},
  author =	 {Ramamonjison, Rindranirina and Yu, Timothy and Li,
                  Raymond and Li, Haley and Carenini, Giuseppe and
                  Ghaddar, Bissan and He, Shiqi and Mostajabdaveh,
                  Mahdi and Banitalebi-Dehkordi, Amin and Zhou, Zirui
                  and Zhang, Yong},
  pages =	 {189-203},
  abstract =	 {The Natural Language for Optimization (NL4Opt)
                  Competition was created to investigate methods of
                  extracting the meaning and formulation of an
                  optimization problem based on its text
                  description. Specifically, the goal of the
                  competition is to increase the accessibility and
                  usability of optimization solvers by allowing
                  non-experts to interface with them using natural
                  language. We separate this challenging goal into two
                  sub-tasks: (1) recognize and label the semantic
                  entities that correspond to the components of the
                  optimization problem; (2) generate a meaning
                  representation (i.e. a logical form) of the problem
                  from its detected problem entities. The first task
                  aims to reduce ambiguity by detecting and tagging
                  the entities of the optimization problems. The
                  second task creates an intermediate representation
                  of the linear programming (LP) problem that is
                  converted into a format that can be used by
                  commercial solvers. In this report, we present the
                  LP word problem dataset and shared tasks for the
                  NeurIPS 2022 competition. Furthermore, we present
                  the winning solutions. Through this competition, we
                  hope to bring interest towards the development of
                  novel machine learning applications and datasets for
                  optimization modeling.},
  section =	 {Competitions}
}

@InProceedings{Kiseleva23a,
  title =	 {Interactive Grounded Language Understanding in a
                  Collaborative Environment: Retrospective on Iglu
                  2022 Competition},
  author =	 {Kiseleva, Julia and Skrynnik, Alexey and Zholus,
                  Artem and Mohanty, Shrestha and Arabzadeh, Negar and
                  C\^{o}t\'e, Marc-Alexandre and Aliannejadi, Mohammad
                  and Teruel, Milagro and Li, Ziming and Burtsev,
                  Mikhail and ter Hoeve, Maartje and Volovikova, Zoya
                  and Panov, Aleksandr and Sun, Yuxuan and Srinet,
                  Kavya and Szlam, Arthur and Awadallah, Ahmed and
                  Rho, Seungeun and Kwon, Taehwan and Wontae Nam,
                  Daniel and Bivort Haiek, Felipe and Zhang, Edwin and
                  Abdrazakov, Linar and Qingyam, Guo and Zhang, Jason
                  and Guo, Zhibin},
  pages =	 {204-216},
  abstract =	 {Human intelligence possesses the extraordinary
                  ability to adapt rapidly to new tasks and
                  multi-modal environments. This capacity emerges at
                  an early age, as humans acquire new skills and learn
                  to solve problems by imitating others or following
                  natural language instructions. To facilitate
                  research in this area, we recently hosted the second
                  \emph{IGLU: Interactive Grounded Language
                  Understanding in a Collaborative Environment}
                  competition. The primary objective of the
                  competition is to address the challenge of creating
                  interactive agents that can learn to solve complex
                  tasks by receiving grounded natural language
                  instructions in a collaborative environment. Given
                  the complexity of this challenge, we divided it into
                  two sub-tasks: first, deciding whether the provided
                  grounded instruction requires clarification, and
                  second, following a clear grounded instruction to
                  complete the task description.},
  section =	 {Competitions}
}

@InProceedings{Ebrahimi23a,
  title =	 {Findings of the Second AmericasNLP Competition on
                  Speech-to-Text Translation},
  author =	 {Ebrahimi, Abteen and Mager, Manuel and Wiemerslage,
                  Adam and Denisov, Pavel and Oncevay, Arturo and Liu,
                  Danni and Koneru, Sai and Ugan, Enes Yavuz and Li,
                  Zhaolin and Niehues, Jan and Romero, Monica and
                  Torre, Ivan G and Alum\"{a}e, Tanel and Kong,
                  Jiaming and Polezhaev, Sergey and Belousov, Yury and
                  Chen, Wei-Rui and Sullivan, Peter and Adebara, Ife
                  and Talafha, Bashar and Inciarte, Alcides Alcoba and
                  Abdul-Mageed, Muhammad and Chiruzzo, Luis and
                  Coto-Solano, Rolando and Cruz, Hilaria and
                  Flores-Sol\'{o}rzano, Sof\'{i}a and L\'{o}pez, Aldo
                  Andr\'{e}s Alvarez and Meza-Ruiz, Ivan and Ortega,
                  John E. and Palmer, Alexis and Salazar, Rodolfo Joel
                  Zevallos and Stenzel, Kristine and Vu, Thang and
                  Kann, Katharina},
  pages =	 {217-232},
  abstract =	 {Indigenous languages, including those from the
                  Americas, have received very little attention from
                  the machine learning (ML) and natural language
                  processing (NLP) communities. To tackle the
                  resulting lack of systems for these languages and
                  the accompanying social inequalities affecting their
                  speakers, we conduct the second AmericasNLP
                  competition (and the first one in collaboration with
                  NeurIPS), which is centered around speech-to-text
                  translation systems for Indigenous languages of the
                  Americas. The competition features three tasks --
                  (1) automatic speech recognition, (2) text-based
                  machine translation, and (3) speech-to-text
                  translation -- and two tracks: constrained and
                  unconstrained. Five Indigenous languages are
                  covered: Bribri, Guarani, Kotiria, Wa'ikhana, and
                  Quechua. In this overview paper, we describe the
                  tasks, tracks, and languages, introduce the baseline
                  and participating systems, and end with a summary of
                  ongoing and future challenges for the automatic
                  translation of Indigenous languages.},
  section =	 {Competitions}
}

@InProceedings{Caggiano23a,
  title =	 {MyoChallenge 2022: Learning contact-rich
                  manipulation using a musculoskeletal hand},
  author =	 {Caggiano, Vittorio and Durandau, Guillaume and Wang,
                  Huwawei and Chiappa, Alberto and Mathis, Alexander
                  and Tano, Pablo and Patel, Nisheet and Pouget,
                  Alexandre and Schumacher, Pierre and Martius, Georg
                  and Haeufle, Daniel and Geng, Yiran and An, Boshi
                  and Zhong, Yifan and Ji, Jiaming and Chen, Yuanpei
                  and Dong, Hao and Yang, Yaodong and Siripurapu,
                  Rahul and Ferro Diez, Luis Eduardo and Kopp, Michael
                  and Patil, Vihang and Hochreiter, Sepp and Tassa,
                  Yuval and Merel, Josh and Schultheis, Randy and
                  Song, Seungmoon and Sartori, Massimo and Kumar,
                  Vikash},
  pages =	 {233-250},
  abstract =	 {Manual dexterity has been considered one of the
                  critical components for human evolution. The ability
                  to perform movements as simple as holding and
                  rotating an object in the hand without dropping it
                  needs the coordination of more than 35 muscles which
                  act synergistically or antagonistically on multiple
                  joints. This complexity in control is markedly
                  different from typical pre-specified movements or
                  torque based controls used in robotics. In the
                  MyoChallenge at the NeurIPS 2022 competition track,
                  we challenged the community to develop controllers
                  for a realistic hand to solve a series of dexterous
                  manipulation tasks. The MyoSuite framework was used
                  to train and test controllers on realistic, contact
                  rich and computation efficient virtual
                  neuromusculoskeletal model of the hand and
                  wrist. Two tasks were proposed: a die re-orientation
                  and a boading ball (rotation of two spheres respect
                  to each other) tasks. More than 40 teams
                  participated to the challenge and submitted more
                  than 340 solutions. The challenge was split in two
                  phases. In the first phase, where a limited set of
                  objectives and randomization were proposed, teams
                  managed to achieve high performance, in particular
                  in the boading-ball task.  In the second phase as
                  the focus shifted towards generalization of task
                  solutions to extensive variations of object and task
                  properties, teams saw significant performance
                  drop. This shows that there is still a large gap in
                  developing agents capable of generalizable skilled
                  manipulation. In future challenges, we will continue
                  pursuing the generalizability both in skills and
                  agility of the tasks exploring additional realistic
                  neuromusculoskeletal models.},
  section =	 {Competitions}
}

@InProceedings{Neun23a,
  title =	 {Traffic4cast at NeurIPS 2022 â€“ Predict Dynamics
                  along Graph Edges from Sparse Node Data: Whole City
                  Traffic and ETA from Stationary Vehicle Detectors},
  author =	 {Neun, Moritz and Eichenberger, Christian and Martin,
                  Henry and Spanring, Markus and Siripurapu, Rahul and
                  Springer, Daniel and Deng, Leyan and Wu, Chenwang
                  and Lian, Defu and Zhou, Min and Lumiste, Martin and
                  Ilie, Andrei and Wu, Xinhua and Lyu, Cheng and Lu,
                  Qing-Long and Mahajan, Vishal and Lu, Yichao and Li,
                  Jiezhang and Li, Junjun and Gong, Yue-Jiao and
                  Gr\"otschla, Florian and Mathys, Jo\"el and Wei, Ye
                  and Haitao, He and Fang, Hui and Malm, Kevin and
                  Tang, Fei and Kopp, Michael and Kreil, David and
                  Hochreiter, Sepp},
  pages =	 {251-278},
  abstract =	 {The global trends of urbanization and increased
                  personal mobility force us to rethink the way we
                  live and use urban space. The Traffic4cast
                  competition series tackles this problem in a
                  data-driven way, advancing the latest methods in
                  machine learning for modeling complex spatial
                  systems over time. In this edition, our dynamic road
                  graph data combine information from road maps,
                  $10^{12}$ probe data points, and stationary vehicle
                  detectors in three cities over the span of two
                  years. While stationary vehicle detectors are the
                  most accurate way to capture traffic volume, they
                  are only available in few locations.  Traffic4cast
                  2022 explores models that have the ability to
                  generalize loosely related temporal vertex data on
                  just a few nodes to predict dynamic future traffic
                  states on the edges of the entire road graph.  In
                  the core challenge, participants are invited to
                  predict the likelihoods of three congestion classes
                  derived from the speed levels in the GPS data for
                  the entire road graph in three cities 15~min into
                  the future. We only provide vehicle count data from
                  spatially sparse stationary vehicle detectors in
                  these three cities as model input for this task. The
                  data are aggregated in 15~min time bins for one hour
                  prior to the prediction time. For the extended
                  challenge, participants are tasked to predict the
                  average travel times on super-segments 15~min into
                  the future -- super-segments are longer sequences of
                  road segments in the graph.  The competition results
                  provide an important advance in the prediction of
                  complex city-wide traffic states just from publicly
                  available sparse vehicle data and without the need
                  for large amounts of real-time floating vehicle
                  data.},
  section =	 {Competitions}
}

@InProceedings{Mazeika23a,
  title =	 {The Trojan Detection Challenge},
  author =	 {Mazeika, Mantas and Hendrycks, Dan and Li, Huichen
                  and Xu, Xiaojun and Hough, Sidney and Zou, Andy and
                  Rajabi, Arezoo and Yao, Qi and Wang, Zihao and Tian,
                  Jian and Tang, Yao and Tang, Di and Smirnov, Roman
                  and Pleskov, Pavel and Benkovich, Nikita and Song,
                  Dawn and Poovendran, Radha and Li, Bo and Forsyth,
                  David.},
  pages =	 {279-291},
  abstract =	 {Neural trojan attacks inject machine learning
                  systems with hidden behavior that lies dormant until
                  activated. In recent years, trojan detection has
                  emerged as a promising avenue for defending against
                  standard trojan attacks. However, there have been
                  few investigations on trojans specifically designed
                  to be difficult to detect. We organized the Trojan
                  Detection Challenge to begin work on the important
                  question of how to build more robust trojan
                  detectors. This paper gives an overview of the
                  competition and its results. Notably, participants
                  greatly improved over strong baselines on trojan
                  detection and reverse-engineering tasks,
                  demonstrating the potential for proactively
                  improving the robustness of trojan detectors. We
                  hope the competition and its results will inspire
                  further research in detecting hidden behavior in
                  machine learning systems.},
  section =	 {Competitions}
}

@InProceedings{Gruca23a,
  title =	 {Weather4cast at NeurIPS 2022: Super-Resolution Rain
                  Movie Prediction under Spatio-temporal Shifts},
  author =	 {Gruca, Aleksandra and Serva, Federico and Lliso,
                  Lloren\c{c} and R\'ipodas, Pilar and Calbet, Xavier
                  and Herruzo, Pedro and Pihrt, Ji\v{r}\'{\i} and
                  Raevskyi, Rudolf and \v{S}im\'{a}nek, Petr and
                  Choma, Matej and Li, Yang and Dong, Haiyu and
                  Belousov, Yury and Polezhaev, Sergey and Pulfer,
                  Brian and Seo, Minseok and Kim, Doyi and Shin,
                  Seungheon and Kim, Eunbin and Ahn, Sewoong and Choi,
                  Yeji and Park, Jinyoung and Son, Minseok and Cho,
                  Seungju and Lee, Inyoung and Kim, Changick and Kim,
                  Taehyeon and Kang, Shinhwan and Shin, Hyeonjeong and
                  Yoon, Deukryeol and Eom, Seongha and Shin, Kijung
                  and Yun, Se-Young and {Le Saux}, Bertrand and Kopp,
                  Michael K and Hochreiter, Sepp and Kreil, David P},
  pages =	 {292-313},
  abstract =	 {Weather4cast again advanced modern algorithms in AI
                  and machine learning through a highly topical
                  interdisciplinary competition challenge: The
                  prediction of hi-res rain radar movies from
                  multi-band satellite sensors, requiring data fusion,
                  multi-channel video frame prediction, and
                  super-resolution. Accurate predictions of rain
                  events are becoming ever more critical, with climate
                  change increasing the frequency of unexpected
                  rainfall. The resulting models will have a
                  particular impact where costly weather radar is not
                  available. We here present highlights and insights
                  emerging from the thirty teams participating from
                  over a dozen countries.  To extract relevant
                  patterns, models were challenged by spatio-temporal
                  shifts.  Geometric data augmentation and test-time
                  ensemble models with a suitable smoother loss helped
                  this transfer learning. Even though, in ablation,
                  static information like geographical location and
                  elevation was not linked to performance, the general
                  success of models incorporating physics in this
                  competition suggests that approaches combining
                  machine learning with application domain knowledge
                  seem a promising avenue for future research.
                  Weather4cast will continue to explore the powerful
                  benchmark reference data set introduced here,
                  advancing competition tasks to quantitative
                  predictions, and exploring the effects of metric
                  choice on model performance and qualitative
                  prediction properties.},
  section =	 {Competitions}
}

@InProceedings{Willeke23a,
  title =	 {Retrospective on the SENSORIUM 2022 competition},
  author =	 {Willeke, Konstantin F. and Fahey, Paul G. and
                  Bashiri, Mohammad and Hansel, Laura and Blessing,
                  Christoph and Lurz, Konstantin-Klemens and Burg, Max
                  F. and Cadena, Santiago A. and Ding, Zhiwei and
                  Ponder, Kayla and Muhammad, Taliah and Patel, Saumil
                  S. and Deng, Kaiwen and Guan, Yuanfang and Zhu,
                  Yiqin and Xiao, Kaiwen and Han, Xiao and Azeglio,
                  Simone and Ferrari, Ulisse and Neri, Peter and
                  Marre, Olivier and Hoffmann, Adrian and Fedyanin,
                  Kirill and Vishniakov, Kirill and Panov, Maxim and
                  Prakash, Subash and Naik, Kishan and Narayanappa,
                  Kantharaju and Ecker, Alexander S. and Tolias,
                  Andreas S. and Sinz, Fabian H.},
  pages =	 {314-333},
  abstract =	 {The neural underpinning of the biological visual
                  system is challenging to study experimentally, in
                  particular as neuronal activity becomes increasingly
                  nonlinear with respect to visual input. Artificial
                  neural networks (ANNs) can serve a variety of goals
                  for improving our understanding of this complex
                  system, not only serving as predictive digital twins
                  of sensory cortex for novel hypothesis generation in
                  silico, but also incorporating bio-inspired
                  architectural motifs to progressively bridge the gap
                  between biological and machine vision. The mouse has
                  recently emerged as a popular model system to study
                  visual information processing, but no standardized
                  large-scale benchmark to identify state-of-the-art
                  models of the mouse visual system has been
                  established. To fill this gap, we proposed the
                  SENSORIUM benchmark competition. We collected a
                  large-scale dataset from mouse primary visual cortex
                  containing the responses of more than 28,000 neurons
                  across seven mice stimulated with thousands of
                  natural images, together with simultaneous
                  behavioral measurements that include running speed,
                  pupil dilation, and eye movements. The benchmark
                  challenge ranked models based on predictive
                  performance for neuronal responses on a held-out
                  test set, and included two tracks for model input
                  limited to either stimulus only (SENSORIUM) or
                  stimulus plus behavior (SENSORIUM+). As a part of
                  the NeurIPS 2022 competition track, we received 172
                  model submissions from 26 teams, with the winning
                  teams improving our previous state-of-the-art model
                  by more than 15 percent. Dataset access and
                  infrastructure for evaluation of model predictions
                  will remain online as an ongoing benchmark. We would
                  like to see this as a starting point for regular
                  challenges and data releases, and as a standard tool
                  for measuring progress in large-scale neural system
                  identification models of the mouse visual system and
                  beyond.},
  section =	 {Competitions}
}
