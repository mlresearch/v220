---
title: 'AutoML Decathlon: Diverse Tasks, Modern Methods, and Efficiency at Scale'
abstract: 'The vision of Automated Machine Learning (AutoML) is to produce high performing
  ML pipelines that require very little human involvement or domain expertise to use.
  Competitions and benchmarks have been critical tools for accelerating progress in
  AutoML. However, much of the prior work on AutoML competitions has focused on well-studied
  domains in machine learning such as vision and language—these are domains which
  have benefited from several years of ML pipeline design by domain experts, which
  brings the usage of AutoML into question in the first place. Recently, AutoML for
  diverse tasks has emerged as an important research area that aims to bring AutoML
  to the domains where it can have the most impact: the long tail of ML tasks <em>beyond
  vision and language</em>. We present a retrospective report of the AutoML Decathlon—an
  AutoML for diverse tasks competition hosted at NeurIPS 2022. The AutoML Decathlon
  presented participants with a set of 10 machine learning tasks that are diverse
  along several axes: domain, input dimension, output dimension, output type, objective
  function, and scale. Participants were tasked with developing AutoML methods that
  performed well on a <em>separate</em> set of 10 hidden diverse test tasks within
  a certain time budget, so as to discourage overfitting to the initial set of tasks
  and to encourage efficiency. In this report, we outline the details of the competition,
  discuss the top-5 submissions, analyze the results, and compare top submissions
  to additional state-of-the-art baselines designed specifically for diverse tasks.
  We conclude that the combination of existing efficient AutoML techniques with modern
  advancements in ML such as large-scale transfer learning, modern architectures,
  and differentiable Neural Architecture Search (NAS) is a promising direction for
  AutoML for diverse tasks.'
section: Competitions
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: roberts22a
month: 0
tex_title: 'AutoML Decathlon: Diverse Tasks, Modern Methods, and Efficiency at Scale'
firstpage: 151
lastpage: 170
page: 151-170
order: 151
cycles: false
bibtex_author: Roberts, Nicholas and Guo, Samuel and Xu, Cong and Talwalkar, Ameet
  and Lander, David and Tao, Lvfang and Cai, Linhang and Niu, Shuaicheng and Heng,
  Jianyu and Qin, Hongyang and Deng, Minwen and Hog, Johannes and Pfefferle, Alexander
  and Shivakumar, Sushil Ammanaghatta and Krishnakumar, Arjun and Wang, Yubo and Sukthanker,
  Rhea and Hutter, Frank and Hasanaj, Euxhen and Le, Tien-Dung and Khodak, Mikhail
  and Nevmyvaka, Yuriy and Rasul, Kashif and Sala, Frederic and Schneider, Anderson
  and Shen, Junhong and Sparks, Evan
author:
- given: Nicholas
  family: Roberts
- given: Samuel
  family: Guo
- given: Cong
  family: Xu
- given: Ameet
  family: Talwalkar
- given: David
  family: Lander
- given: Lvfang
  family: Tao
- given: Linhang
  family: Cai
- given: Shuaicheng
  family: Niu
- given: Jianyu
  family: Heng
- given: Hongyang
  family: Qin
- given: Minwen
  family: Deng
- given: Johannes
  family: Hog
- given: Alexander
  family: Pfefferle
- given: Sushil Ammanaghatta
  family: Shivakumar
- given: Arjun
  family: Krishnakumar
- given: Yubo
  family: Wang
- given: Rhea
  family: Sukthanker
- given: Frank
  family: Hutter
- given: Euxhen
  family: Hasanaj
- given: Tien-Dung
  family: Le
- given: Mikhail
  family: Khodak
- given: Yuriy
  family: Nevmyvaka
- given: Kashif
  family: Rasul
- given: Frederic
  family: Sala
- given: Anderson
  family: Schneider
- given: Junhong
  family: Shen
- given: Evan
  family: Sparks
date: 2023-08-31
address:
container-title: Proceedings of the NeurIPS 2022 Competitions Track
volume: '220'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 8
  - 31
pdf: https://proceedings.mlr.press/v220/roberts22a/roberts22a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
